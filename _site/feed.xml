<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">Heuristics:Commentary Generator</title>
<subtitle type="text">Commentary Generator</subtitle>
<generator uri="https://github.com/mojombo/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="/feed.xml" />
<link rel="alternate" type="text/html" href="" />
<updated>2015-01-29T04:34:15-05:00</updated>
<id>/</id>
<author>
  <name>Team Heuristics</name>
  <uri>/</uri>
  <email>siddhantmanocha1994@gmail.com</email>
</author>


<entry>
  <title type="html"><![CDATA[Tennis Ball Detection and Tracking]]></title>
  <link rel="alternate" type="text/html" href="/articles/ball" />
  <id>/articles/ball</id>
  <published>2015-01-29T00:00:00-05:00</published>
  <updated>2015-01-29T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;h3 id=&quot;why-is-there-a-separate-post-for-this&quot;&gt;Why is there a separate post for this?&lt;/h3&gt;
&lt;p&gt;Observe a video of a tennis match and notice if you can see the ball at all times. The answer is no. Even our eyes- one of the finest visual detectors cannot keep track of the ball. This is because of two reasons:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;The ball is a very small object compared to the other objects in the frame.&lt;/li&gt;
  &lt;li&gt;It moves very fast during a match sequece.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All this made ball tracking a challenge.&lt;/p&gt;

&lt;h3 id=&quot;initial-attempts&quot;&gt;Initial attempts:&lt;/h3&gt;
&lt;p&gt;We had already had an amazing experience with the efficiency of RCNN. So we decided to give it a shot- and included the tennis ball in one of the classes that it should be detecting in the frame.
The result? The ball could not be detected. &lt;/p&gt;

&lt;h3 id=&quot;what-next&quot;&gt;What next?&lt;/h3&gt;
&lt;p&gt;One of the key features that made the ball different from all the other objects in the frame was its fast motion. And that could be utilized to detect it. We started with using the Luke Kanade optical flow to see if the ball could be detected. Although this approach had one major flaw- it first tracks the object and then monitors its motion. And in most of the cases, the algorithm was not able to detect the ball in the first place.
Luckily for us, we found an approach that gave significant weightage to the motion of the object in the detection process.&lt;/p&gt;

&lt;p&gt;Detecting of the position and velocity of the ball using Thomas Brox’s optical flow:
The algorithm for optical flow by Thomas Brox took into account the high-speed motion of relatively smaller objects in the frame- something that no other optical flow manages. 
So given two consecutive frames in a video, we can detect the speed and direction of motion of the large as well as the smaller objects. The output is observed in the optical flow wheel coloring scheme. 
Here is the exact sequence of steps:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Break the video into its constituent frames.&lt;/li&gt;
  &lt;li&gt;Apply optical flow for pairwise frames, to obtain velocity map of the objects.&lt;/li&gt;
  &lt;li&gt;Perform morphological processing on the obtained maps to retain the players and the ball. (Since the players and ball will have considerably high speed as compared to everything else on the court, we can threshhold the intensity of the velocity map.&lt;/li&gt;
  &lt;li&gt;Using connected component analysis, obtain the ball (assuming it will be the component of the smallest area).&lt;/li&gt;
  &lt;li&gt;Using the optical flow color wheel, obtain the direction and magnitude of the ball’s velocity.&lt;/li&gt;
&lt;/ul&gt;


  &lt;p&gt;&lt;a href=&quot;/articles/ball&quot;&gt;Tennis Ball Detection and Tracking&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 29, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Recognizing actions in videos]]></title>
  <link rel="alternate" type="text/html" href="/articles/action" />
  <id>/articles/action</id>
  <published>2015-01-19T00:00:00-05:00</published>
  <updated>2015-01-19T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Hi guys.. What does a commentary contain? It mostly contains actions performed by players. So, Inorder to generate a commentary, recognizing actions is one of the most crucial thing. Actions? What actions are you talking about??? Right now we confined to 3 actions which states whether a player is serving the ball or hitting the ball or neither of them.  &lt;/p&gt;

&lt;p&gt;Ok. How are we going to recognize actions then! We are going to train an Autonomous system which on giving some motion based features of the video as input, outputs the action performed by players. Wait! What are motion based features? They are some kind of information extracted out of motion of various objects (I mean group of pixels) that can be understood by computer. There are several motion based features. Examples include Histogram of Optical Flow(HOF),  3D Histogram of Oriented Gradients (HOG3D). &lt;/p&gt;

&lt;p&gt;What next? Training the system to recognize actions. But that requires a dataset for supervising the system. We tried to find some datasets for tennis action recognition which contain input motion based features and their corresponding output. We found a dataset that was developed by ACASVA team. The dataset contains HOG3D features of bounding boxes drawn over players. It also contains corresponding actions of players. &lt;/p&gt;

&lt;p&gt;Hurray!!! Let’s start training then. But there is a small problem. The way in which the bounding boxes are drawn and the way in which HOG3D features are computed is not revealed in microdetails. Training it is not a problem since we have dataset. But, applying to a new video is a problem which requires computation of HOG3D features of new video. So, unfortunately this idea was dropped. &lt;/p&gt;

&lt;p&gt;So, we need to start searching for more datasets or create the dataset on our own.&lt;/p&gt;

&lt;p&gt;Link to ACASVA dataset: http://www.cvssp.org/acasva/Downloads&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/articles/action&quot;&gt;Recognizing actions in videos&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 19, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Introduction to HOF features]]></title>
  <link rel="alternate" type="text/html" href="/articles/HOF" />
  <id>/articles/HOF</id>
  <published>2015-01-19T00:00:00-05:00</published>
  <updated>2015-01-19T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Good morning guys.. In last blog, I talked about motion based features. Now it’s time to delve into depth a bit and talk about one of the most commonly used ones - Histogram of Optical Flow (HOF).&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/articles/HOF&quot;&gt;Introduction to HOF features&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 19, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Introduction to HOG3d features]]></title>
  <link rel="alternate" type="text/html" href="/articles/HOG3d" />
  <id>/articles/HOG3d</id>
  <published>2015-01-18T00:00:00-05:00</published>
  <updated>2015-01-18T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;h3 id=&quot;desciption-and-usage-of-hog3d-features&quot;&gt;Desciption and usage of HOG3d Features&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://cloud.githubusercontent.com/assets/10415819/5792312/97c6b236-9f38-11e4-828d-c382d0155e49.png&quot; alt=&quot;HOG3d&quot; /&gt;
This Blog is a basic introduction to we did for the Winter School program and our successes and failures.&lt;/p&gt;

&lt;p&gt;Our Idea was to create an AI System that can generate Automatic commentary for Tennis matches.&lt;/p&gt;

&lt;p&gt;We broke down the problem to few blocks so that we can divide the work amongst ourselves and work on the same.&lt;/p&gt;

&lt;p&gt;They were  as follows-&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Player Detection&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Action Recognition&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;&lt;strong&gt;Commentary generation&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First we had to decide what features to use for detecting the action.This is a serious problem in Computer Vision.We went through few research papers and found that Calculation of local Spatio-Temporal Interest Points would be going forward in some direction.The Research paper is found &lt;a href=&quot;http://www.irisa.fr/vista/Papers/2009_bmvc_wang.pdf&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Basically,it uses a combination of HOG3D(Histogram Of Gradients) and HOF(Histogram of Optical Flow) to detect some interest point which might be an indicator of the action performed by a person.&lt;/p&gt;

&lt;p&gt;The Code for calculating the STIP detector and descriptor can be found &lt;a href=&quot;http://www.di.ens.fr/~laptev/download.html&quot;&gt;here&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;Although we managed to view a demo version of the code and see what it does(with help from &lt;a href=&quot;http://web.michaelchughes.com/how-to/install-stip-software-with-opencv-v2&quot;&gt;this&lt;/a&gt; website ),we were unable to make changes to it since it was dependent on a much older version of OpenCV which was 2.3.The binaries are already compiled and they require the OpenCV libraries of that version.&lt;/p&gt;

&lt;p&gt;The Latest version is 3.0.0 and i was using the 2.4.9 version.So after installing required version as well,we were unable to make any sort of changes to it as it was leading to a build error when we used Cmake.&lt;/p&gt;

&lt;p&gt;Hence we dropped the idea of using STIP and tried using HOF Features and the details of which can be view in the blog post written by my friend.&lt;/p&gt;

&lt;p&gt;The Action Recognition requires calculation of large amounts of data and it seemed tedious and inefficient to track unnecessary movements such as player walking,ball-boys running etc.&lt;/p&gt;

&lt;p&gt;So,to increase the efficiency of the Action Recognition algorithm,we started working on the Audio Analysis of the input Video.The basic understanding is that actions such as serve and hit are performed only when the ball hits the racquet and this is accompanied by the ‘plopp!’ sound(Honestly i tried searching for the right word to describe the sound but i found this!Others may describe it as Pock!/Plock! whatever.Well you know what i am talking about anyways :D )&lt;/p&gt;

&lt;p&gt;If we can detect the time interval at which we know that sound is detected,then we can use that to increase the probability of our Action Recognition Algorithm’s results at that instant accordingly.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/articles/HOG3d&quot;&gt;Introduction to HOG3d features&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 18, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Court Detection]]></title>
  <link rel="alternate" type="text/html" href="/articles/rcnn5" />
  <id>/articles/rcnn5</id>
  <published>2015-01-17T00:00:00-05:00</published>
  <updated>2015-01-17T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Court Detection is crucial for obtaining informations and making inferences for a tennis match and generate interesting commentary.We took to the task of court detection with the following objectives.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Filter the players from other persons in the image&lt;/li&gt;
  &lt;li&gt;Make inferences on the position of the players with respect to the court and the type of shot being 	played&lt;/li&gt;
  &lt;li&gt;Filtering the frames which contain match sequence from the video&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Court Detection was important but was a non trivial problem. We approached the problem in two different ways.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Finding straight lines in the image (Hough Transforms)&lt;/li&gt;
  &lt;li&gt;Template Matching (Homographic Transforms)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;hough-transforms&quot;&gt;Hough Transforms&lt;/h3&gt;

&lt;p&gt;We made an assumption that most distict white colored lines in a image of tennis match comes from the court. Applying specific filters on the S channel for HSV representation of the image, we were able to generate a binary image with distinct court lines. We then applied morphology transformation, namely erosion and dilation successively to make the lines more prominent.Applying hough transform on the binary image gave the following results.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d1.png&quot; alt=&quot;RCNN Results&quot; /&gt;
&lt;img src=&quot;/images/d3.png&quot; alt=&quot;RCNN Results&quot; /&gt;
&lt;img src=&quot;/images/d5.png&quot; alt=&quot;RCNN Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;As is evident from the results, the method did not give complete court lines and detected only a part of them. Also the method did not work in case of clay courts where the white lines were not too distict or there were white objects in the background.&lt;/p&gt;

&lt;p&gt;We tried to resolve the first issue by picking up points on the detected lines and trying to find the best fit lines through these set of points. The horizontal lines were detected by constraints on the slope of fitted line but other two non parallel lines of the court could not be detected by this approach. So we tried to apply homographic transforms.&lt;/p&gt;

&lt;h3 id=&quot;homographic-transforms&quot;&gt;Homographic Transforms&lt;/h3&gt;

&lt;p&gt;The tennis courts have the same shape but are captured by different cameras at different angles. Thus there must exist a transformation with respect to the scale and the rotation such that one tennis court can be obtained from the other. Under this asumption, we used homographic transforms or template matching.This required us to fix a template and find the transformation of specific points on the template and find their location on a test image. &lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/template123.jpg&quot; alt=&quot;RCNN Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Template&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d25.png&quot; alt=&quot;RCNN Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d29.png&quot; alt=&quot;RCNN Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/d86.png&quot; alt=&quot;RCNN Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Results&lt;/p&gt;

&lt;p&gt;Thus it is quite clear that clear inferences cannot be made regarding the court with homographic transformations as well. Thus we aim to combine the results of hough transforms with homographic transforms and try to obtain results from sequence of images rather than single image for better results.&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/articles/rcnn5&quot;&gt;Court Detection&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 17, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Object Detection with RCNN]]></title>
  <link rel="alternate" type="text/html" href="/articles/rcnn4" />
  <id>/articles/rcnn4</id>
  <published>2015-01-17T00:00:00-05:00</published>
  <updated>2015-01-17T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Our project had started to progress after we had done all the background work, installed the required toolboxes and collected relevant data. &lt;/p&gt;

&lt;p&gt;RCNN is the state of art visual object detection system, which uses the region proposals obtained via selective search with the convoluted neural networks.It is built upon the caffe deep learning framework. The toolbox is well documented and offers demo codes to demonstrate its usage. We utilised pre trained model which was trained on the imagenet dataset for the task of extracting tennis players from the video frames.&lt;/p&gt;

&lt;p&gt;RCNN toolbox offers a demo code with the name rcnn_demo.m under the &lt;code&gt;examples&lt;/code&gt; foler. It makes a call to the function named showboxes.m defined under the &lt;code&gt;vis&lt;/code&gt; folder. ImageNet dataset has a large number of objects with around 200 labelled class of objects with classes as &lt;code&gt;person&lt;/code&gt;, &lt;code&gt;racket&lt;/code&gt;,&lt;code&gt;ball&lt;/code&gt;, etc.The demo code returns the score of all the classes which may be found in the image together with the location of the bounding boxes around that object in the image.Since we were only interested in the person class we set a threshold on the score upto which regions will be reported and filtered the person class from other classes.&lt;/p&gt;

&lt;p&gt;The results from RCNN were fairly accurate and are illustrated below.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/images/final2.png&quot; alt=&quot;RCNN Results&quot; /&gt;&lt;/p&gt;

&lt;p&gt;But since it detected a lot of extra regions for the person class, as the refree and the ball boys, we have to filter them out and extract precise information of the players only. Thus we took to our next objective of detecting the court which can filter the players from other persons present in the scene. Also, court detection gave information regarding the the players location with respect to the court, distiguish between frames with match sequence from other frames, and make other interesting inferences.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/articles/rcnn4&quot;&gt;Object Detection with RCNN&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 17, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Caffe with RCNN Installation]]></title>
  <link rel="alternate" type="text/html" href="/articles/rcnn2" />
  <id>/articles/rcnn2</id>
  <published>2015-01-17T00:00:00-05:00</published>
  <updated>2015-01-17T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Caffe is the deep learning framework created by a Phd student at UC Berkeley. It is well documented and has easy installation instructions. Information on the framework can be found at http://caffe.berkeleyvision.org/ . But we had a different problem altogether. We were not provided sudo access on the GPU. As a results we cannot install any software as a root user. Fortunately, most of the dependencies as Blas, Open CV, Cuda libraries, etc were already installed. Three of the dependencies namely glog, gflag, lmdb were not installed and had to be installed from the source files. This took some time but was figured out.&lt;/p&gt;

&lt;p&gt;A lot of libraries were depreciated and required some workaround. Most of such errors were rectified step by step. We ran the installer and tried to correct the errors thrown during the installation. This required us to locate the new names for the missing files via &lt;code&gt;locate&lt;/code&gt; command in linux and link them to the correct part via &lt;code&gt;ln -s destination source&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;We used Anaconda for the python dependencies and this required us to include google.protobuf in python sys.path (search it present as installation of python 2.7 generally) which was shown to be missing. The issues page on github repositories provided specific help, for example: one such instance required us to rename the libm.so file in the lib folder in the anaconda python distribution.&lt;/p&gt;

&lt;p&gt;After caffe installation, the rcnn installation was pretty straightforward and we just cloned the repository and followed the steps mentioned.&lt;/p&gt;

&lt;p&gt;After much effort, we were able to install the caffe framework with rcnn and we could run our first cnn( convoluted neural net) code for object detection.&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;/articles/rcnn2&quot;&gt;Caffe with RCNN Installation&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 17, 2015.&lt;/p&gt;</content>
</entry>


<entry>
  <title type="html"><![CDATA[Start of a Wonderful Experience]]></title>
  <link rel="alternate" type="text/html" href="/articles/rcnn" />
  <id>/articles/rcnn</id>
  <published>2015-01-17T00:00:00-05:00</published>
  <updated>2015-01-17T00:00:00-05:00</updated>
  <author>
    <name>Team Heuristics</name>
    <uri></uri>
    <email>siddhantmanocha1994@gmail.com</email>
  </author>
  <content type="html">&lt;p&gt;Last year I visited CMU-NITK Winter School organised by Carnegie Mellon University at National Institute of Technology, Karnataka. It was a wonderful opportunity and exposed me to large number of interesting topics in the field of machine learning.&lt;/p&gt;

&lt;p&gt;The Winter School began on 10 December. After some introductory lectures, we were asked to brainstorm and come up with some interesting ideas that we would like to execute in a short span of just 15 days. This whole procedure was quite interesting and we came across a lot of interesting ideas. We had a group of four team members each from different background. This was very helpful as it exposed us to lot of new interesting ideas and approaches.&lt;/p&gt;

&lt;p&gt;Despite the fact that we had only a span of 15 days for the project, we came up with a rather ambitious idea. We decided to make an application that can generate commentary for any match given just its video. This was an interesting problem and more importantly it was a great learning experience.&lt;/p&gt;

&lt;p&gt;After some excellent guidance from the mentors, we were able to modularize the whole problem statement into discrete parts. Owing to the non availability of data, we restricted ourselves to generation of commentary for tennis matches. Given a video of a tennis match, we tried to find the key elements that can characterise the important information of the match. We divided the whole problem statement as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Court Detection&lt;/li&gt;
  &lt;li&gt;Object Recognition&lt;/li&gt;
  &lt;li&gt;Action Recognition&lt;/li&gt;
  &lt;li&gt;Audio Analysis&lt;/li&gt;
  &lt;li&gt;Ball tracking&lt;/li&gt;
  &lt;li&gt;Commentary Generation&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We divided the task among the four team members and set on to our tasks individually. However, we had to face a lot of challenges in the early phase before we can formalise our approach. The major drawback  was the non availability of action labelled data for any sports dataset. We were not left with any other choice but to annotate data ourselves. We created a HTML 5 application utilising HTML 5 canvas that required the user to move around the rectangles, find the bounding box for the action region and label the corresponding part. We will try improving the code and provide it as an annotation tool as well share the annotated sports action dataset for tennis matches.&lt;/p&gt;

&lt;p&gt;Next, we plunged to the job of object recognition. We discovered that RCNN (Regions with Convoluted Neural Networks) gave pretty superior results for object recognition as compared to other techniques and had a pre trained model on imagenet dataset which can be used directly. Since running the code for RCNN required a GPU, we were provided GPU access from IIT Bombay. Thereafter this began the next challenging part, installation of caffe and rcnn toolbox on the GPU………………&lt;/p&gt;

  &lt;p&gt;&lt;a href=&quot;/articles/rcnn&quot;&gt;Start of a Wonderful Experience&lt;/a&gt; was originally published by Team Heuristics at &lt;a href=&quot;&quot;&gt;Heuristics:Commentary Generator&lt;/a&gt; on January 17, 2015.&lt;/p&gt;</content>
</entry>

</feed>